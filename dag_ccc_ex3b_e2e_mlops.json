{
  "pipelineSpec": {
    "components": {
      "comp-preprocess": {
        "executorLabel": "exec-preprocess",
        "inputDefinitions": {
          "artifacts": {
            "staged_bq_table": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "app_prefix": {
              "type": "STRING"
            },
            "excluded_columns": {
              "type": "STRING"
            },
            "gcs_pipeline_root": {
              "type": "STRING"
            },
            "target_column": {
              "type": "STRING"
            },
            "user_id_column": {
              "type": "STRING"
            },
            "weight_column": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "staged_test_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "staged_training_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "staged_validation_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-simpledeploy": {
        "executorLabel": "exec-simpledeploy",
        "inputDefinitions": {
          "artifacts": {
            "hmodel": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "app_prefix": {
              "type": "STRING"
            },
            "serving_machine_type": {
              "type": "STRING"
            },
            "serving_max_replica": {
              "type": "INT"
            },
            "serving_min_replica": {
              "type": "INT"
            },
            "vertexai_experiment_name": {
              "type": "STRING"
            },
            "vertexai_projectid": {
              "type": "STRING"
            },
            "vertexai_region": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-stage": {
        "executorLabel": "exec-stage",
        "inputDefinitions": {
          "parameters": {
            "bq_dataset": {
              "type": "STRING"
            },
            "bq_projectid": {
              "type": "STRING"
            },
            "bq_table": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-train": {
        "executorLabel": "exec-train",
        "inputDefinitions": {
          "artifacts": {
            "staged_test_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "staged_training_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "staged_validation_dataset": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "app_prefix": {
              "type": "STRING"
            },
            "excluded_columns": {
              "type": "STRING"
            },
            "gcs_pipeline_root": {
              "type": "STRING"
            },
            "target_column": {
              "type": "STRING"
            },
            "user_id_column": {
              "type": "STRING"
            },
            "vertexai_experiment_name": {
              "type": "STRING"
            },
            "vertexai_projectid": {
              "type": "STRING"
            },
            "vertexai_region": {
              "type": "STRING"
            },
            "weight_column": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-preprocess": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "preprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'fsspec' 'gcsfs' 'scikit-learn' 'kfp==1.8.14' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef preprocess(gcs_pipeline_root: str,\n               app_prefix: str,\n               user_id_column: str,\n               target_column: str,\n               weight_column: str,\n               excluded_columns: list,\n               staged_bq_table: InputPath('staged_bq_table'), \n               staged_training_dataset: OutputPath('staged_training_dataset'), \n               staged_validation_dataset: OutputPath('staged_validation_dataset'), \n               staged_test_dataset: OutputPath('staged_test_dataset')):\n\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n\n    dataset = pd.read_csv(staged_bq_table, index_col=0)\n\n\n    ## drop excluded columns\n    ndataset = dataset.drop(excluded_columns, axis =1)\n\n    X = ndataset.loc[:, ndataset.columns != target_column]\n    Y = ndataset.loc[:, ndataset.columns == target_column]\n    ## Feature engineering if any, e.g\n    ## from sklearn.preprocessing import MinMaxScaler\n    ## scaler = MinMaxScaler(feature_range = (0,1))\n    ## scaler.fit(X)\n\n    ## Split dataset into training, validation and testing sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=101)\n\n    training_dataset = pd.concat([X_train,Y_train], axis = 1)\n    validation_dataset = pd.concat([X_val,Y_val], axis = 1)\n    test_dataset = pd.concat([X_test,Y_test], axis = 1)\n\n    ## Stage training, validation and testing datasets to GCS\n    training_dataset.to_csv(staged_training_dataset, index = False)\n    validation_dataset.to_csv(staged_validation_dataset,index = False)\n    test_dataset.to_csv(staged_test_dataset, index = False)\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-simpledeploy": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "simpledeploy"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'fsspec' 'gcsfs' 'scikit-learn' 'google-cloud-aiplatform' 'kfp==1.8.14' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef simpledeploy(hmodel: Input[Model],\n          vertexai_experiment_name:str, \n          vertexai_region: str, \n          vertexai_projectid: str,\n          app_prefix: str,\n          serving_machine_type: str,\n          serving_min_replica: int,\n          serving_max_replica: int           \n         ):\n\n     from google.cloud import aiplatform \n\n     aiplatform.init(\n       project=vertexai_projectid,\n       location=vertexai_region\n     )\n\n     ## auxiliary variables\n     model_name = f\"{app_prefix}_model_exc3b_mlops\"\n     endpoint_name = f\"{app_prefix}_endpoint_exc3b_mlops\"\n     model_path = hmodel.path\n\n     ##check if model is already registered in Vertex AI Model Registry\n     model_filter_str='labels.experiment_name=\"'+vertexai_experiment_name+'\"'\n     print(\"Model filter string: \"+model_filter_str)\n\n     models = aiplatform.Model.list(\n        filter=model_filter_str\n     )\n\n     model_labels = {\n          \"experiment_name\": vertexai_experiment_name\n     }\n\n     if len(models)>0:\n        model_exists = True\n        model = models[0]\n\n        vertexai_model = aiplatform.Model.upload_tensorflow_saved_model(\n          display_name = model_name,\n          parent_model = model.resource_name,\n          saved_model_dir = model_path,\n          labels = model_labels,\n          is_default_version = True\n        )\n     else: \n        vertexai_model = aiplatform.Model.upload_tensorflow_saved_model(\n          display_name = model_name,\n          saved_model_dir = model_path,\n          labels = model_labels,\n          is_default_version = True\n        )\n\n\n     ##same story for endpoint - check if exists - if not create it and then deploy new model to it. \n     endpoint_filter_str='labels.experiment_name=\"'+vertexai_experiment_name+'\"'\n     endpoints = aiplatform.Endpoint.list(\n       filter=endpoint_filter_str,\n     )\n\n     endpoint_labels = {\n         \"experiment_name\": vertexai_experiment_name\n     }\n\n     if len(endpoints)>0:\n       endpoint = endpoints[0]\n       deployed_models = endpoint.list_models()\n       for dmodel in deployed_models:\n           print(dmodel.display_name)\n     else: \n        endpoint = aiplatform.Endpoint.create(\n          display_name = endpoint_name,\n          labels = endpoint_labels   \n        )\n\n     #### Deploy model to endpoint\n     endpoint.deploy(\n       model = vertexai_model,\n       traffic_percentage = 100,\n       machine_type=serving_machine_type,\n       min_replica_count=serving_min_replica,\n       max_replica_count=serving_max_replica\n     )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-stage": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "stage"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'db-dtypes' 'google-cloud-bigquery' 'pyarrow' 'kfp==1.8.14' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef stage(bq_projectid: str, bq_dataset: str, bq_table: str, output_dataset: OutputPath('staged_bq_table')):\n    from google.cloud import bigquery\n    import google.auth\n\n    ##authenticate \n    auth_credentials, auth_project = google.auth.default()\n    print(\"Project: \"+auth_project)\n    client = bigquery.Client(project=bq_projectid, credentials = auth_credentials)\n\n\n    query = f\"SELECT * FROM {bq_projectid}.{bq_dataset}.{bq_table}\"\n    print(query)\n\n    ## fetch query results as dataframe\n    dataframe = client.query(query).to_dataframe()\n    print(dataframe.head()) \n\n    ## export resultset into csv file om GCS\n    dataframe.to_csv(output_dataset)\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-train": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "train"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'fsspec' 'gcsfs' 'scikit-learn' 'google-cloud-aiplatform' 'keras_tuner' 'kfp==1.8.14' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef train(staged_training_dataset: InputPath('staged_training_dataset'), \n          staged_validation_dataset: InputPath('staged_validation_dataset'), \n          staged_test_dataset: InputPath('staged_test_dataset'),\n          vertexai_experiment_name:str, \n          vertexai_region: str, \n          vertexai_projectid: str,\n          gcs_pipeline_root: str,\n          app_prefix: str, \n          user_id_column: str,\n          target_column: str,\n          weight_column: str,\n          excluded_columns: list,\n          output_model: Output[Model]\n         ):\n\n     import tensorflow as tf\n     import keras_tuner\n     from google.cloud import aiplatform\n     from datetime import datetime\n     import pandas as pd\n\n\n     _METRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n     ]\n\n     ## function to build model\n     def build_model(hptune):\n        model = tf.keras.Sequential()\n        model.add(tf.keras.layers.Dense(units=32, activation = \"relu\"))\n        model.add(\n           tf.keras.layers.Dense(\n              # Define the hyperparameter\n              units=32, ##hptune.Int(\"units\", min_value=32, max_value=96, step=32),\n              activation=\"relu\" ##hptune.Choice(\"activation\",[\"relu\",\"tanh\"]),\n                )\n        )\n        if hptune.Boolean(\"dropout\"):\n           model.add(tf.keras.layers.Dropout(rate=0.25))\n\n        model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n        learning_rate = 1e-4 ##hptune.Float(\"lr\",min_value = 1e-4, max_value=1e-2, sampling=\"log\")\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n            loss=tf.keras.losses.BinaryCrossentropy(), \n            metrics=_METRICS,\n        )\n        return model\n\n     training_dataset = pd.read_csv(staged_training_dataset)\n     validation_dataset = pd.read_csv(staged_validation_dataset)\n     test_dataset = pd.read_csv(staged_test_dataset)\n\n\n     feature_columns = [column for column in training_dataset.columns if  column != target_column]\n     target_columns = [target_column]\n\n     x_train = training_dataset[feature_columns]\n     y_train = training_dataset[target_columns]\n\n     x_val = validation_dataset[feature_columns]\n     y_val = validation_dataset[target_columns]\n\n     x_test = test_dataset[feature_columns]\n     y_test = test_dataset[target_columns]\n\n     trials_dir=f\"{app_prefix}_trials\"\n     ##Create a Keras Hyperband Hyperparameter tuner with an accuracy objective\n     tuner =  keras_tuner.Hyperband(\n       hypermodel=build_model,\n       objective=keras_tuner.Objective(\"precision\", direction=\"max\"),\n       max_epochs=2,\n       factor=3,\n       hyperband_iterations=1,\n       seed=None,\n       hyperparameters=None,\n       tune_new_entries=True,\n       allow_new_entries=True,\n       directory=trials_dir\n     )\n\n     weight_for_0 = 0.5 ##(1 / neg) * (total / 2.0)\n     weight_for_1 = 20  ##(1 / pos) * (total / 2.0)\n\n     class_weights = {0: weight_for_0, 1: weight_for_1}\n     stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n     output = tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val) , callbacks=[stop_early], class_weight=class_weights)\n\n     # Get the optimal hyperparameters for the model as determined from the search\n     best_hyperparameters=tuner.get_best_hyperparameters()[0]\n     hypermodel = tuner.hypermodel.build(best_hyperparameters)\n     history = hypermodel.fit(x_train, y_train, epochs=2, validation_data=(x_val, y_val))\n\n     results = hypermodel.evaluate(x_test, y_test)\n\n     #### SAVE MODEL\n     print(output_model.path)\n     model_path = output_model.path\n     hypermodel.save(model_path)\n\n\n     aiplatform.init(\n       project=vertexai_projectid,\n       location=vertexai_region,\n       experiment=vertexai_experiment_name\n     )\n\n     run_id = f\"run-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n     run = aiplatform.start_run(run_id)\n\n     training_params = {\n        'training_dataset': staged_training_dataset,\n        'validation_dataset': staged_validation_dataset,\n        'test_dataset': staged_test_dataset,\n        'model_type': 'nn',\n        'model_path': model_path,\n        'trainedby': app_prefix, \n        ##'hp_units': best_hyperparameters.get('units'),\n        ##'hp_activation': best_hyperparameters.get('activation'),\n        'hp_dropout': best_hyperparameters.get('dropout'),\n        ##'hp_lr': best_hyperparameters.get('lr'),\n     }\n\n     training_metrics = {\n        'model_loss': results[0],\n        'model_accuracy': results[5],\n        'model_precision': results[6],\n        'model_recall': results[7],\n        'model_auc': results[8],\n        'model_prc': results[9],\n        'model_tp': results[1],\n        'model_fp': results[2],\n        'model_tn': results[3],\n        'model_fn': results[4]\n     }\n\n     run.log_params(training_params)\n     run.log_metrics(training_metrics)\n\n\n     classification_metrics = run.log_classification_metrics(\n       display_name='classification metrics',\n       labels=['Positive', 'Negative'],\n       matrix=[[results[1], results[2]], [results[4], results[3]]],\n       fpr=[],\n       tpr=[],\n       threshold=[],\n     )\n\n     run.end_run()\n\n"
            ],
            "image": "us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "wf-kubeflow-e2e-mlops"
    },
    "root": {
      "dag": {
        "tasks": {
          "preprocess": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-preprocess"
            },
            "dependentTasks": [
              "stage"
            ],
            "inputs": {
              "artifacts": {
                "staged_bq_table": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_dataset",
                    "producerTask": "stage"
                  }
                }
              },
              "parameters": {
                "app_prefix": {
                  "componentInputParameter": "in_app_prefix"
                },
                "excluded_columns": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "[\"synerise_client_id\", \"weight\"]"
                    }
                  }
                },
                "gcs_pipeline_root": {
                  "componentInputParameter": "in_pipeline_root"
                },
                "target_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "y_if_trans"
                    }
                  }
                },
                "user_id_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "synerise_client_id"
                    }
                  }
                },
                "weight_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "weight"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "preprocess"
            }
          },
          "simpledeploy": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-simpledeploy"
            },
            "dependentTasks": [
              "train"
            ],
            "inputs": {
              "artifacts": {
                "hmodel": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_model",
                    "producerTask": "train"
                  }
                }
              },
              "parameters": {
                "app_prefix": {
                  "componentInputParameter": "in_app_prefix"
                },
                "serving_machine_type": {
                  "componentInputParameter": "in_serving_machine_type"
                },
                "serving_max_replica": {
                  "componentInputParameter": "in_serving_max_replica"
                },
                "serving_min_replica": {
                  "componentInputParameter": "in_serving_min_replica"
                },
                "vertexai_experiment_name": {
                  "componentInputParameter": "in_vertexai_experiment_name"
                },
                "vertexai_projectid": {
                  "componentInputParameter": "in_vertexai_projectid"
                },
                "vertexai_region": {
                  "componentInputParameter": "in_vertexai_region"
                }
              }
            },
            "taskInfo": {
              "name": "simpledeploy"
            }
          },
          "stage": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-stage"
            },
            "inputs": {
              "parameters": {
                "bq_dataset": {
                  "componentInputParameter": "in_bq_dataset"
                },
                "bq_projectid": {
                  "componentInputParameter": "in_bq_projectid"
                },
                "bq_table": {
                  "componentInputParameter": "in_bq_table"
                }
              }
            },
            "taskInfo": {
              "name": "stage"
            }
          },
          "train": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-train"
            },
            "dependentTasks": [
              "preprocess"
            ],
            "inputs": {
              "artifacts": {
                "staged_test_dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "staged_test_dataset",
                    "producerTask": "preprocess"
                  }
                },
                "staged_training_dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "staged_training_dataset",
                    "producerTask": "preprocess"
                  }
                },
                "staged_validation_dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "staged_validation_dataset",
                    "producerTask": "preprocess"
                  }
                }
              },
              "parameters": {
                "app_prefix": {
                  "componentInputParameter": "in_app_prefix"
                },
                "excluded_columns": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "[\"synerise_client_id\", \"weight\"]"
                    }
                  }
                },
                "gcs_pipeline_root": {
                  "componentInputParameter": "in_pipeline_root"
                },
                "target_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "y_if_trans"
                    }
                  }
                },
                "user_id_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "synerise_client_id"
                    }
                  }
                },
                "vertexai_experiment_name": {
                  "componentInputParameter": "in_vertexai_experiment_name"
                },
                "vertexai_projectid": {
                  "componentInputParameter": "in_vertexai_projectid"
                },
                "vertexai_region": {
                  "componentInputParameter": "in_vertexai_region"
                },
                "weight_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "weight"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "train"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "in_app_prefix": {
            "type": "STRING"
          },
          "in_bq_dataset": {
            "type": "STRING"
          },
          "in_bq_projectid": {
            "type": "STRING"
          },
          "in_bq_table": {
            "type": "STRING"
          },
          "in_pipeline_root": {
            "type": "STRING"
          },
          "in_serving_machine_type": {
            "type": "STRING"
          },
          "in_serving_max_replica": {
            "type": "INT"
          },
          "in_serving_min_replica": {
            "type": "INT"
          },
          "in_vertexai_experiment_name": {
            "type": "STRING"
          },
          "in_vertexai_projectid": {
            "type": "STRING"
          },
          "in_vertexai_region": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.14"
  },
  "runtimeConfig": {}
}